{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EIP3_session6_assignemnt.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpniosNranke",
        "colab_type": "text"
      },
      "source": [
        "### Assignment\n",
        "1. Go through this Post: https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/ (Links to an external site.) <br>\n",
        "2. Add these improvements to the final code described in the post: <br>\n",
        "3. Predict 500 characters only <br>\n",
        "4. Remove all the punctuation from the source text <br>\n",
        "5. Train the model on padded sequences (Links to an external site.) rather than random sequences of characters.  <br>\n",
        "6. Train the model for 100 epochs <br>\n",
        "7. Add dropout to the input layer, remove it from the layer before dense layer. Use Dropout value of 0.1 everywhere \n",
        "8. Submit! <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4id9loHamgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load LSTM network and generate text\n",
        "import sys\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ8TGhMHAYMN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c4740b6f-b613-43c9-9606-b7c19fe657e4"
      },
      "source": [
        "# Mount google drive to store check point model results.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AYFeZRWalQm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbhwiSYvalmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hA38U64AbYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify gdrive path to load input file\n",
        "import os \n",
        "filename = \"/content/gdrive/My Drive/EIP3/wonderland.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A-gw2YwAAQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load ascii text and covert to lowercase\n",
        "#filename = \"wonderland.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2D7nZyG8p8W",
        "colab_type": "text"
      },
      "source": [
        "### Remove punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD8BKXXstCiE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "73c3d124-6635-4f1b-bcb3-46b1868b3be1"
      },
      "source": [
        "# define punctuation\n",
        "punctuations = '''`!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "\n",
        "#my_str = \"Hello!!!, he said ---and went.\"\n",
        "\n",
        "# To take input from the user\n",
        "# my_str = input(\"Enter a string: \")\n",
        "\n",
        "def remove_punc(raw_text):\n",
        "  # remove punctuation from the string\n",
        "  no_punct = \"\"\n",
        "  for char in raw_text:\n",
        "    if char not in punctuations:\n",
        "      no_punct = no_punct + char\n",
        "  return no_punct\n",
        "# display the unpunctuated string\n",
        "#print(no_punct)\n",
        "\n",
        "raw_text = remove_punc(raw_text)\n",
        "print raw_text[:1000]"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alices adventures in wonderland\n",
            "\n",
            "                alices adventures in wonderland\n",
            "\n",
            "                          lewis carroll\n",
            "\n",
            "               the millennium fulcrum edition 30\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            chapter i\n",
            "\n",
            "                      down the rabbithole\n",
            "\n",
            "\n",
            "  alice was beginning to get very tired of sitting by her sister\n",
            "on the bank and of having nothing to do  once or twice she had\n",
            "peeped into the book her sister was reading but it had no\n",
            "pictures or conversations in it and what is the use of a book\n",
            "thought alice without pictures or conversation\n",
            "\n",
            "  so she was considering in her own mind as well as she could\n",
            "for the hot day made her feel very sleepy and stupid whether\n",
            "the pleasure of making a daisychain would be worth the trouble\n",
            "of getting up and picking the daisies when suddenly a white\n",
            "rabbit with pink eyes ran close by her\n",
            "\n",
            "  there was nothing so very remarkable in that nor did alice\n",
            "think it so very much out of the way to hear the rabbit say to\n",
            "itself oh dear  oh dear  i shall be\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyUWwBJ5C33c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "850733fc-4863-4b77-821e-ab641bb57ff8"
      },
      "source": [
        "raw_text[:100]"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'alices adventures in wonderland\\n\\n                alices adventures in wonderland\\n\\n                  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G43uxaHjAICO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9fd8026d-4c1b-4fc9-accd-e0909d81c0c3"
      },
      "source": [
        "# create mapping of unique chars to integers, and a reverse mapping\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print \"Total Characters: \", n_chars\n",
        "print \"Total Vocab: \", n_vocab\n"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  140265\n",
            "Total Vocab:  30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PUrQwK2C8QB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "outputId": "1d2973a5-6f8d-4352-f5b8-2090419b7099"
      },
      "source": [
        "char_to_int\n",
        "int_to_char\n"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '\\n',\n",
              " 1: ' ',\n",
              " 2: '0',\n",
              " 3: '3',\n",
              " 4: 'a',\n",
              " 5: 'b',\n",
              " 6: 'c',\n",
              " 7: 'd',\n",
              " 8: 'e',\n",
              " 9: 'f',\n",
              " 10: 'g',\n",
              " 11: 'h',\n",
              " 12: 'i',\n",
              " 13: 'j',\n",
              " 14: 'k',\n",
              " 15: 'l',\n",
              " 16: 'm',\n",
              " 17: 'n',\n",
              " 18: 'o',\n",
              " 19: 'p',\n",
              " 20: 'q',\n",
              " 21: 'r',\n",
              " 22: 's',\n",
              " 23: 't',\n",
              " 24: 'u',\n",
              " 25: 'v',\n",
              " 26: 'w',\n",
              " 27: 'x',\n",
              " 28: 'y',\n",
              " 29: 'z'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WFAOZIiC3Cf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2938da29-a53a-4ed3-b775-e8569f2c23f3"
      },
      "source": [
        "\n",
        "148574-100"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "148474"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULyvAZih9Dmx",
        "colab_type": "text"
      },
      "source": [
        "### Added Padded sequence with input sequece "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgCmi3KQALuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f89771a7-f698-483a-90b3-73da7eb3192f"
      },
      "source": [
        " \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "  seq_in = raw_text[i:i + seq_length]\n",
        "  seq_out = raw_text[i + seq_length]\n",
        "  \n",
        "  ## padded sequence\n",
        "  idx = numpy.random.randint(0, seq_length)\n",
        "  temp_x = ([char_to_int[char] for char in seq_in])\n",
        "  len_temp_X = len(temp_x)\n",
        "  temp_X = temp_x[idx:len(temp_x)]\n",
        "  dataX.append(temp_X)\n",
        "  dataY.append(char_to_int[seq_out])\n",
        "  \n",
        "  dataX.append([char_to_int[char] for char in seq_in])\n",
        "  dataY.append(char_to_int[seq_out])\n",
        "\n",
        "dataXX = pad_sequences(dataX).tolist()\n",
        "print type(dataX)\n",
        "print type(dataXX)\n",
        "n_patterns = len(dataXX)\n",
        "print \"Total Patterns: \", n_patterns\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataXX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)\n"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<type 'list'>\n",
            "<type 'list'>\n",
            "Total Patterns:  280330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP30D8Ztfygj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0b-GFal9Q_v",
        "colab_type": "text"
      },
      "source": [
        "### Added dropout 0.1 to input and removed dropout on output layer\n",
        "### check point of best model stored in gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLrOh0rZAPds",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86e555a3-5ab3-44e8-a995-5a0201308598"
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# define the checkpoint\n",
        "checkpoint = \"/content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\"\n",
        "\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(checkpoint, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=100, batch_size=2048, callbacks=callbacks_list)\n"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "280330/280330 [==============================] - 95s 338us/step - loss: 2.8734\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.87339, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 2/100\n",
            "280330/280330 [==============================] - 99s 354us/step - loss: 2.8306\n",
            "\n",
            "Epoch 00002: loss improved from 2.87339 to 2.83057, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 3/100\n",
            "280330/280330 [==============================] - 105s 375us/step - loss: 2.7646\n",
            "\n",
            "Epoch 00003: loss improved from 2.83057 to 2.76456, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 4/100\n",
            "280330/280330 [==============================] - 106s 379us/step - loss: 2.6176\n",
            "\n",
            "Epoch 00004: loss improved from 2.76456 to 2.61764, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 5/100\n",
            "280330/280330 [==============================] - 101s 361us/step - loss: 2.4800\n",
            "\n",
            "Epoch 00005: loss improved from 2.61764 to 2.48004, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 6/100\n",
            "280330/280330 [==============================] - 91s 323us/step - loss: 2.3708\n",
            "\n",
            "Epoch 00006: loss improved from 2.48004 to 2.37078, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 7/100\n",
            "280330/280330 [==============================] - 91s 324us/step - loss: 2.2656\n",
            "\n",
            "Epoch 00007: loss improved from 2.37078 to 2.26565, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 8/100\n",
            "280330/280330 [==============================] - 97s 348us/step - loss: 2.1764\n",
            "\n",
            "Epoch 00008: loss improved from 2.26565 to 2.17640, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 9/100\n",
            "280330/280330 [==============================] - 103s 366us/step - loss: 2.1049\n",
            "\n",
            "Epoch 00009: loss improved from 2.17640 to 2.10493, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 10/100\n",
            "280330/280330 [==============================] - 106s 379us/step - loss: 2.0315\n",
            "\n",
            "Epoch 00010: loss improved from 2.10493 to 2.03153, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 11/100\n",
            "280330/280330 [==============================] - 106s 378us/step - loss: 1.9721\n",
            "\n",
            "Epoch 00011: loss improved from 2.03153 to 1.97207, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 12/100\n",
            "280330/280330 [==============================] - 100s 356us/step - loss: 1.9211\n",
            "\n",
            "Epoch 00012: loss improved from 1.97207 to 1.92112, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 13/100\n",
            "280330/280330 [==============================] - 102s 364us/step - loss: 1.8744\n",
            "\n",
            "Epoch 00013: loss improved from 1.92112 to 1.87436, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 14/100\n",
            "280330/280330 [==============================] - 106s 379us/step - loss: 1.8335\n",
            "\n",
            "Epoch 00014: loss improved from 1.87436 to 1.83348, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 15/100\n",
            "280330/280330 [==============================] - 106s 378us/step - loss: 1.7971\n",
            "\n",
            "Epoch 00015: loss improved from 1.83348 to 1.79712, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 16/100\n",
            "280330/280330 [==============================] - 93s 333us/step - loss: 1.7638\n",
            "\n",
            "Epoch 00016: loss improved from 1.79712 to 1.76376, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 17/100\n",
            "280330/280330 [==============================] - 90s 322us/step - loss: 1.7304\n",
            "\n",
            "Epoch 00017: loss improved from 1.76376 to 1.73038, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 18/100\n",
            "280330/280330 [==============================] - 99s 354us/step - loss: 1.7000\n",
            "\n",
            "Epoch 00018: loss improved from 1.73038 to 1.69999, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 19/100\n",
            "280330/280330 [==============================] - 105s 376us/step - loss: 1.6720\n",
            "\n",
            "Epoch 00019: loss improved from 1.69999 to 1.67197, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 20/100\n",
            "280330/280330 [==============================] - 105s 373us/step - loss: 1.6438\n",
            "\n",
            "Epoch 00020: loss improved from 1.67197 to 1.64385, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 21/100\n",
            "280330/280330 [==============================] - 104s 372us/step - loss: 1.6193\n",
            "\n",
            "Epoch 00021: loss improved from 1.64385 to 1.61929, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 22/100\n",
            "280330/280330 [==============================] - 105s 376us/step - loss: 1.5971\n",
            "\n",
            "Epoch 00022: loss improved from 1.61929 to 1.59707, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 23/100\n",
            "280330/280330 [==============================] - 102s 364us/step - loss: 1.5713\n",
            "\n",
            "Epoch 00023: loss improved from 1.59707 to 1.57125, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 24/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 1.5491\n",
            "\n",
            "Epoch 00024: loss improved from 1.57125 to 1.54908, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 25/100\n",
            "280330/280330 [==============================] - 90s 322us/step - loss: 1.5253\n",
            "\n",
            "Epoch 00025: loss improved from 1.54908 to 1.52534, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 26/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 1.5028\n",
            "\n",
            "Epoch 00026: loss improved from 1.52534 to 1.50279, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 27/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 1.4796\n",
            "\n",
            "Epoch 00027: loss improved from 1.50279 to 1.47960, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 28/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 1.4564\n",
            "\n",
            "Epoch 00028: loss improved from 1.47960 to 1.45640, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 29/100\n",
            "280330/280330 [==============================] - 98s 348us/step - loss: 1.4327\n",
            "\n",
            "Epoch 00029: loss improved from 1.45640 to 1.43270, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 30/100\n",
            "280330/280330 [==============================] - 105s 376us/step - loss: 1.4116\n",
            "\n",
            "Epoch 00030: loss improved from 1.43270 to 1.41163, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 31/100\n",
            "280330/280330 [==============================] - 100s 356us/step - loss: 1.3878\n",
            "\n",
            "Epoch 00031: loss improved from 1.41163 to 1.38780, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 32/100\n",
            "280330/280330 [==============================] - 90s 322us/step - loss: 1.3621\n",
            "\n",
            "Epoch 00032: loss improved from 1.38780 to 1.36212, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 33/100\n",
            "280330/280330 [==============================] - 90s 322us/step - loss: 1.3374\n",
            "\n",
            "Epoch 00033: loss improved from 1.36212 to 1.33743, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 34/100\n",
            "280330/280330 [==============================] - 90s 322us/step - loss: 1.3125\n",
            "\n",
            "Epoch 00034: loss improved from 1.33743 to 1.31255, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 35/100\n",
            "280330/280330 [==============================] - 90s 322us/step - loss: 1.2883\n",
            "\n",
            "Epoch 00035: loss improved from 1.31255 to 1.28827, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 36/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 1.2587\n",
            "\n",
            "Epoch 00036: loss improved from 1.28827 to 1.25871, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 37/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 1.2353\n",
            "\n",
            "Epoch 00037: loss improved from 1.25871 to 1.23529, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 38/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 1.2072\n",
            "\n",
            "Epoch 00038: loss improved from 1.23529 to 1.20716, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 39/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 1.1789\n",
            "\n",
            "Epoch 00039: loss improved from 1.20716 to 1.17892, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 40/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 1.1536\n",
            "\n",
            "Epoch 00040: loss improved from 1.17892 to 1.15359, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 41/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 1.1238\n",
            "\n",
            "Epoch 00041: loss improved from 1.15359 to 1.12377, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 42/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 1.0977\n",
            "\n",
            "Epoch 00042: loss improved from 1.12377 to 1.09774, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 43/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 1.0697\n",
            "\n",
            "Epoch 00043: loss improved from 1.09774 to 1.06972, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 44/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 1.0464\n",
            "\n",
            "Epoch 00044: loss improved from 1.06972 to 1.04636, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 45/100\n",
            "280330/280330 [==============================] - 90s 322us/step - loss: 1.0205\n",
            "\n",
            "Epoch 00045: loss improved from 1.04636 to 1.02047, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 46/100\n",
            "280330/280330 [==============================] - 90s 322us/step - loss: 0.9944\n",
            "\n",
            "Epoch 00046: loss improved from 1.02047 to 0.99438, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 47/100\n",
            "280330/280330 [==============================] - 90s 322us/step - loss: 0.9716\n",
            "\n",
            "Epoch 00047: loss improved from 0.99438 to 0.97156, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 48/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 0.9449\n",
            "\n",
            "Epoch 00048: loss improved from 0.97156 to 0.94489, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 49/100\n",
            "280330/280330 [==============================] - 90s 322us/step - loss: 0.9201\n",
            "\n",
            "Epoch 00049: loss improved from 0.94489 to 0.92015, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 50/100\n",
            "280330/280330 [==============================] - 90s 322us/step - loss: 0.8994\n",
            "\n",
            "Epoch 00050: loss improved from 0.92015 to 0.89937, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 51/100\n",
            "280330/280330 [==============================] - 103s 366us/step - loss: 0.8760\n",
            "\n",
            "Epoch 00051: loss improved from 0.89937 to 0.87597, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 52/100\n",
            "280330/280330 [==============================] - 105s 376us/step - loss: 0.8554\n",
            "\n",
            "Epoch 00052: loss improved from 0.87597 to 0.85542, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 53/100\n",
            "280330/280330 [==============================] - 104s 372us/step - loss: 0.8343\n",
            "\n",
            "Epoch 00053: loss improved from 0.85542 to 0.83430, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 54/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 0.8175\n",
            "\n",
            "Epoch 00054: loss improved from 0.83430 to 0.81753, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 55/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 0.7987\n",
            "\n",
            "Epoch 00055: loss improved from 0.81753 to 0.79865, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 56/100\n",
            "280330/280330 [==============================] - 90s 322us/step - loss: 0.7778\n",
            "\n",
            "Epoch 00056: loss improved from 0.79865 to 0.77782, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 57/100\n",
            "280330/280330 [==============================] - 90s 322us/step - loss: 0.7598\n",
            "\n",
            "Epoch 00057: loss improved from 0.77782 to 0.75975, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 58/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 0.7443\n",
            "\n",
            "Epoch 00058: loss improved from 0.75975 to 0.74429, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 59/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 0.7265\n",
            "\n",
            "Epoch 00059: loss improved from 0.74429 to 0.72652, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 60/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 0.7104\n",
            "\n",
            "Epoch 00060: loss improved from 0.72652 to 0.71039, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 61/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 0.6942\n",
            "\n",
            "Epoch 00061: loss improved from 0.71039 to 0.69421, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 62/100\n",
            "280330/280330 [==============================] - 90s 322us/step - loss: 0.6774\n",
            "\n",
            "Epoch 00062: loss improved from 0.69421 to 0.67740, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 63/100\n",
            "280330/280330 [==============================] - 90s 322us/step - loss: 0.6661\n",
            "\n",
            "Epoch 00063: loss improved from 0.67740 to 0.66605, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 64/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 0.6489\n",
            "\n",
            "Epoch 00064: loss improved from 0.66605 to 0.64891, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 65/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 0.6373\n",
            "\n",
            "Epoch 00065: loss improved from 0.64891 to 0.63727, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 66/100\n",
            "280330/280330 [==============================] - 90s 323us/step - loss: 0.6279\n",
            "\n",
            "Epoch 00066: loss improved from 0.63727 to 0.62789, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 67/100\n",
            "280330/280330 [==============================] - 91s 323us/step - loss: 0.6108\n",
            "\n",
            "Epoch 00067: loss improved from 0.62789 to 0.61082, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 68/100\n",
            "280330/280330 [==============================] - 91s 323us/step - loss: 0.5984\n",
            "\n",
            "Epoch 00068: loss improved from 0.61082 to 0.59837, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 69/100\n",
            "280330/280330 [==============================] - 91s 323us/step - loss: 0.5865\n",
            "\n",
            "Epoch 00069: loss improved from 0.59837 to 0.58651, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 70/100\n",
            "280330/280330 [==============================] - 91s 323us/step - loss: 0.5757\n",
            "\n",
            "Epoch 00070: loss improved from 0.58651 to 0.57567, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 71/100\n",
            "280330/280330 [==============================] - 91s 323us/step - loss: 0.5675\n",
            "\n",
            "Epoch 00071: loss improved from 0.57567 to 0.56753, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 72/100\n",
            "280330/280330 [==============================] - 91s 323us/step - loss: 0.5559\n",
            "\n",
            "Epoch 00072: loss improved from 0.56753 to 0.55591, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 73/100\n",
            "280330/280330 [==============================] - 91s 323us/step - loss: 0.5429\n",
            "\n",
            "Epoch 00073: loss improved from 0.55591 to 0.54292, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 74/100\n",
            "280330/280330 [==============================] - 91s 324us/step - loss: 0.5304\n",
            "\n",
            "Epoch 00074: loss improved from 0.54292 to 0.53041, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 75/100\n",
            "280330/280330 [==============================] - 91s 323us/step - loss: 0.5223\n",
            "\n",
            "Epoch 00075: loss improved from 0.53041 to 0.52227, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 76/100\n",
            "280330/280330 [==============================] - 91s 324us/step - loss: 0.5150\n",
            "\n",
            "Epoch 00076: loss improved from 0.52227 to 0.51501, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 77/100\n",
            "280330/280330 [==============================] - 91s 324us/step - loss: 0.5076\n",
            "\n",
            "Epoch 00077: loss improved from 0.51501 to 0.50759, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 78/100\n",
            "280330/280330 [==============================] - 91s 324us/step - loss: 0.4948\n",
            "\n",
            "Epoch 00078: loss improved from 0.50759 to 0.49479, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 79/100\n",
            "280330/280330 [==============================] - 91s 324us/step - loss: 0.4875\n",
            "\n",
            "Epoch 00079: loss improved from 0.49479 to 0.48753, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 80/100\n",
            "280330/280330 [==============================] - 91s 324us/step - loss: 0.4766\n",
            "\n",
            "Epoch 00080: loss improved from 0.48753 to 0.47664, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 81/100\n",
            "280330/280330 [==============================] - 91s 324us/step - loss: 0.4711\n",
            "\n",
            "Epoch 00081: loss improved from 0.47664 to 0.47115, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 82/100\n",
            "280330/280330 [==============================] - 91s 323us/step - loss: 0.4625\n",
            "\n",
            "Epoch 00082: loss improved from 0.47115 to 0.46247, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 83/100\n",
            "280330/280330 [==============================] - 91s 323us/step - loss: 0.4536\n",
            "\n",
            "Epoch 00083: loss improved from 0.46247 to 0.45364, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 84/100\n",
            "280330/280330 [==============================] - 91s 323us/step - loss: 0.4476\n",
            "\n",
            "Epoch 00084: loss improved from 0.45364 to 0.44763, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 85/100\n",
            "280330/280330 [==============================] - 91s 324us/step - loss: 0.4392\n",
            "\n",
            "Epoch 00085: loss improved from 0.44763 to 0.43916, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 86/100\n",
            "280330/280330 [==============================] - 91s 324us/step - loss: 0.4345\n",
            "\n",
            "Epoch 00086: loss improved from 0.43916 to 0.43448, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 87/100\n",
            "280330/280330 [==============================] - 91s 323us/step - loss: 0.4279\n",
            "\n",
            "Epoch 00087: loss improved from 0.43448 to 0.42786, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 88/100\n",
            "280330/280330 [==============================] - 91s 324us/step - loss: 0.4199\n",
            "\n",
            "Epoch 00088: loss improved from 0.42786 to 0.41989, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 89/100\n",
            "280330/280330 [==============================] - 91s 324us/step - loss: 0.4129\n",
            "\n",
            "Epoch 00089: loss improved from 0.41989 to 0.41288, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 90/100\n",
            "280330/280330 [==============================] - 91s 323us/step - loss: 0.4052\n",
            "\n",
            "Epoch 00090: loss improved from 0.41288 to 0.40519, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 91/100\n",
            "280330/280330 [==============================] - 91s 323us/step - loss: 0.4013\n",
            "\n",
            "Epoch 00091: loss improved from 0.40519 to 0.40128, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 92/100\n",
            "280330/280330 [==============================] - 91s 323us/step - loss: 0.3963\n",
            "\n",
            "Epoch 00092: loss improved from 0.40128 to 0.39629, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 93/100\n",
            "280330/280330 [==============================] - 91s 324us/step - loss: 0.3918\n",
            "\n",
            "Epoch 00093: loss improved from 0.39629 to 0.39176, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 94/100\n",
            "280330/280330 [==============================] - 91s 324us/step - loss: 0.3844\n",
            "\n",
            "Epoch 00094: loss improved from 0.39176 to 0.38442, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 95/100\n",
            "280330/280330 [==============================] - 91s 324us/step - loss: 0.3795\n",
            "\n",
            "Epoch 00095: loss improved from 0.38442 to 0.37949, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 96/100\n",
            "280330/280330 [==============================] - 91s 324us/step - loss: 0.3758\n",
            "\n",
            "Epoch 00096: loss improved from 0.37949 to 0.37577, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 97/100\n",
            "280330/280330 [==============================] - 91s 324us/step - loss: 0.3707\n",
            "\n",
            "Epoch 00097: loss improved from 0.37577 to 0.37074, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 98/100\n",
            "280330/280330 [==============================] - 91s 323us/step - loss: 0.3671\n",
            "\n",
            "Epoch 00098: loss improved from 0.37074 to 0.36709, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 99/100\n",
            "280330/280330 [==============================] - 91s 324us/step - loss: 0.3635\n",
            "\n",
            "Epoch 00099: loss improved from 0.36709 to 0.36353, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n",
            "Epoch 100/100\n",
            "280330/280330 [==============================] - 91s 323us/step - loss: 0.3532\n",
            "\n",
            "Epoch 00100: loss improved from 0.36353 to 0.35323, saving model to /content/gdrive/My Drive/EIP3/assignment6_v3.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff7e2ca2990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3zj06e-YvY3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "ab0d78c8-1f10-4d83-d823-0f3370904422"
      },
      "source": [
        "\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataXX)-1)\n",
        "pattern = dataXX[start]\n",
        "print \"Seed:\"\n",
        "print \"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\"\n",
        "# generate characters\n",
        "for i in range(500):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "  #patten.concatinate(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print \"\\nDone.\""
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\"  another hedgehog\n",
            "which seemed to alice an excellent opportunity for croqueting one\n",
            "of them with the \"\n",
            " other  the only difficulty was that her\n",
            "flamingo mike a serpent wiich sald the cortth \n",
            "  the fant ruite licker nutt be the said this she said in a hoaring anowh\n",
            "eeil hfr foeam of the senew ane denne sn the things beooss the gande\n",
            "   i dadalt begin thich wpulder as she hett to gnennny down hye held\n",
            "\n",
            "  she moment she waid to herself as she ran while she was sallen anynhing beoots in the pepple and tee whth all the restent said and were ouierfly    aying nother afoue as she mefth gersilg sp co so \n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdV3zYndY-21",
        "colab_type": "text"
      },
      "source": [
        "#### Conclusion\n",
        "* Have implemented larger LSTM Recurrent Neural Network <br>\n",
        "* Removed punctuation from Input data set.<br>\n",
        "* Added dropout 0.1 to input layer and removed dropout from output layer.<br>\n",
        "* Total number of sequence in the input data is  1,48,474 and after added a one padded sequence for each sequence in each in the input layer, total number of sequence is 2,80,330 <br>\n",
        "* Have generated a random seed and made model to predict next 500 character in that sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu-E5VQnaOb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}